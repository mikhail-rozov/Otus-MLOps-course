Предыдущая итерация проекта - [Конвейер подготовки данных](https://github.com/mikhail-rozov/Otus-MLOps-course/tree/32ddd65d9c3c183eff29dfee20a4535036d44216/20_%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B0._%D0%9A%D0%BE%D0%BD%D0%B2%D0%B5%D0%B9%D0%B5%D1%80_%D0%BF%D0%BE%D0%B4%D0%B3%D0%BE%D1%82%D0%BE%D0%B2%D0%BA%D0%B8_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85)  
<br>
Скрипт DAG'а Airflow - [airflow_script.py](airflow_script.py)  
Скрипт очистки данных - [data_cleaning.py](data_cleaning.py)  
Скрипт обучения модели - [regular_refitting.py](regular_refitting.py)  
<br>  
Airflow каждые сутки автоматически создаёт кластер из 4-х нод на сервисе Yandex Cloud.  
На кластере с помощью PySpark происходит распределённое выполнение скрипта очистки данных, результаты обработки сохраняются в S3-хранилище. Скрипт проводит оценку того, какие данные уже были обработаны, а какие поступили на обработку впервые. Обрабатываются только новые данные и добавляются к уже обработанным.  
При наличии новых данных на кластере автоматически запускается скрипт обучения модели классификации, производящий также предварительную трансформацию данных. Скрипт проводит подбор гиперпараметров модели, оценку итоговой модели на тестовой выборке и логгирование метрик и гиперпараметров в MLflow. Также в MLflow сохраняются артефакты прогона скрипта, включая настройки окружения и файл модели.  
После всех операций Airflow запускает удаление кластера для экономии средств. При отсутствии новых данных за сутки, скрипт очистки данных не проводит очистку, а сохраняет информацию об отсутствии новых данных в S3. Airflow считывает эту информацию и пропускает запуск скрипта обучения модели, сразу приступая к удалению кластера.  
Обучение проводилось всего на двух текстовых файлах данных из 40, чтобы всё уместилось в разумное время. Два текстовых файла содержат 282 млн. строк.  
К сожалению, полученная метрика roc-auc оказалась лишь чуть выше метрики случайного предсказания. Связываю это с недостаточным feature engineering из-за нехватки времени, а также из-за недостаточной информации о значении отдельных признаков. Ну и это не являлось основной целью данной домашней работы.
<br>  

Конфигурация виртуальных машин, сопровождающих процесс (должны работать постоянно):

<img src="https://github.com/user-attachments/assets/432ea1cd-f017-4e92-8190-06e0948d67f2" width="1000" height="175" />  
<br>
Postgres поднимался на обычной виртуальной машине, без использования Yandex Managed Service for PostgreSQL, так как полноценная инфраструктура postgres в данной задаче не нужна, и это оказалось дешевле более, чем в 2 раза. База данных запускалась в docker-контейнере.

Ссылка на Dockerfile postgres - [Dockerfile](Dockerfile)

Для MLflow сначала устанавливались все зависимости, далее запускался bash-скрипт для поднятия сервера.

Ссылка на скрипт сервера MLflow (пример без секреток) - [run_mlflow_server_example.sh](run_mlflow_server_example.sh)

Граф полноценного прогона Airflow:  

<img src="https://github.com/user-attachments/assets/c1491be0-4fac-452d-a0c3-ccb59a58fe79" width="700" height="250" />  
<br>  

Граф прогона Airflow в случае отсутствия новых данных:  

<img src="https://github.com/user-attachments/assets/557681f1-9886-41c8-ae58-0fd63ec579d5" width="700" height="250" />  
<br>  

Скриншот интерфейса MLflow:  

<img src="https://github.com/user-attachments/assets/cb2b9e97-9be0-4fad-9b20-3cceef980170" width="1000" height="500" />  
<br>  

Артефакты MLflow в S3-хранилище:  

<img src="https://github.com/user-attachments/assets/18c9e774-4ccb-408a-9846-1d0a0e00e728" width="700" height="300" />  
<br>  

Скриншот содержимого таблицы metrics базы данных postgres:  

<img src="https://github.com/user-attachments/assets/8a8bf7e0-fe9c-42e0-a214-f58c95b650f9" width="600" height="100" />  
<br>  
