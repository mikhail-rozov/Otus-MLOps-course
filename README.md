## Домашние задания:  

Домашние задания представляют собой части одного проекта, поэтому каждое следующее задание использует наработки предыдущего. Исходными данными для задачи является датасет объёмом более 100 ГБ (2 млрд. строк) в сыром (текстовом) виде. Датасет содержит информацию о транзакциях, часть из которых является мошенническими. Модель будет классифицировать транзакции в распределённой среде.  

### 1. <ins>[Конвейер подготовки данных](https://github.com/mikhail-rozov/Otus-MLOps-course/tree/master/20_Практика._Конвейер_подготовки_данных)</ins>  

Автоматическое по расписанию (Airflow) создание кластера в облаке (Yandex cloud), загрузка новых данных из S3-хранилища (boto3), распределённая очистка этих данных (PySpark), выгрузка очищенных данных в S3-хранилище, удаление кластера.  

### 2. <ins>[Регулярное переобучение](https://github.com/mikhail-rozov/Otus-MLOps-course/tree/master/25_Практика_Регулярное%20переобучение)</ins>   

Автоматическое распределённое переобучение модели классификации на новых данных (PySparkML) с подбором гиперпараметров в облачном кластере. Логирование метрик и оптимальных гиперпараметров модели в MLflow, поднятый на отдельном сервере и подключённый к базе данных PostgreSQL, также поднятой на отдельном сервере. Сохранение артефактов в S3 (окружение и обученная модель).  

### 3. <ins>[Автоматическая валидация](https://github.com/mikhail-rozov/Otus-MLOps-course/tree/master/30_Практика._Автоматическая%20валидация)</ins>   

Метрика теперь считается на бутстрап-выборках для получения распределения метрики. Далее проводится статистический t-тест (scipy.stats) для сравнения средней метрики новой модели с предыдущей. В случае получения статистически значимого улучшения метрики, новая модель сохраняется в MLflow с её метрикой и p-value теста.  

### 4. <ins>[Асинхронный потоковый режим](https://github.com/mikhail-rozov/Otus-MLOps-course/tree/master/32_Асинхронный_потоковый_режим)</ins>   

Потоковое чтение новых данных из Kafka, предсказание модели в кластере и отправка результата обратно в Kafka. Логирование объёма потока поступающих данных и производительности кластера с моделью для определения необходимости масштабирования мощностей кластера.  

### 5. <ins>[Курсовой проект](https://github.com/mikhail-rozov/otus-course-project)</ins>   
Данный курсовой проект является кульминацией обучения и всех домашних заданий. Те же операции проделаны на другом датасете и дополнительно добавлено CI/CD через Github Actions с автоматической сборкой образа с новой моделью и развёртывание образа в кластере Kubernetes с автоматическим масштабированием.