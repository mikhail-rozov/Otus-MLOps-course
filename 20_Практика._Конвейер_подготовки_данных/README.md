Скрипт DAG'а Airflow - [airflow_script.py](airflow_script.py)  
Скрипт очистки данных - [data_cleaning.py](data_cleaning.py)  
<br>  
Airflow каждые сутки (здесь - 15 минут для более быстрого выполнения 3-х запусков) автоматически создаёт кластер из 4-х нод, распределённо выполняет на нём скрипт очистки данных, сохраняет результаты обработки в S3-хранилище, после чего удаляет кластер для экономии финансов. Скрипт проводит оценку того, какие данные уже были обработаны, а какие поступили на обработку впервые. Обрабатываются только новые данные и добавляются к уже обработанным.  
<br>  
Скриншот интерфейса Airflow с успешно выполненным 3 раза DAG'ом:

<img src="https://github.com/mikhail-rozov/Otus-MLOps-course/assets/77928025/254ff711-dbf0-4f7d-9585-59df3b87b33b" width="750" height="421" />
