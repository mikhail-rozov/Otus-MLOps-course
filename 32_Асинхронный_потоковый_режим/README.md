### Асинхронный режим. Обработка данных на потоке.

Скрипт DAG'а Airflow - [airflow_script.py](airflow_script.py)

В данном практическом задании Airflow поднимает кластер из 4 нод, на котором производится инференс модели, обученной в [предыдущей практической работе](https://github.com/mikhail-rozov/Otus-MLOps-course/tree/master/30_Практика._Автоматическая%20валидация). Скрипт инференса ([model_inference.py](model_inference.py)) загружает модель из MLflow, берёт данные из Кафки батчами, производит их обработку, отправляет данные на инференс модели. Предсказания модели по классификации мошеннических транзакций отправляются обратно в Кафку.  
Согласно условию практического задания, число обработанных моделью транзакций в секунду фиксируется и отправляется в MLflow. Также было интересно посмотреть, сколько необработанных транзакций в секунду поступает в Кафку, как бы имитируя реальный поток данных, поэтому соответствующая метрика также логгировалась в MLflow.  

Серверы Airflow, MLflow, Postgres поднимались в Яндекс облаке, как и в предыдущем практическом задании. Кластер Kafka также поднимался в облаке Яндекса (сервис Managed Service for Apache Kafka®). В качестве источника данных выступала моя домашняя машина, которая продюсила данные из файла в Кафку ([kafka_producer.py](kafka_producer.py)). Файл имеет более 40 млн строк (транзакций), и, чтобы его отправить целиком, машине требуется более 20 минут, так что для данного эксперимента данных было достаточно. Данные отправлялись батчами, по 50 тыс. транзакций.  
<br>
<ins>Результаты:</ins>  
<img src="https://github.com/user-attachments/assets/707e9cae-f562-47a4-b876-c1c0a998dcc3" width="1000" height="450" />  

На скриншоте видно, что кластер смог обрабатывать максимум 13 тыс. транзакций в секунду, при этом источник генерировал около 30 тыс. График скорости инференса имеет довольно интересный вид, с падениями производительности практически до нуля. Возможно, нужна доработка алгоритма с упором на особенности инференса модели на Spark-кластере, а, возможно, дело в особенностях работы с Кафкой. Изучение этого вопроса выходит за рамки данного практического занятия.  

Также, для сравнения, прикладываю результаты работы кластера из 2 нод (мастер + 1 воркер). Это тестовый прогон, где проверял работоспособность алгоритма, но, думаю, интересно это сюда добавить и сравнить:  
<img src="https://github.com/user-attachments/assets/d1782eaf-1269-4b01-a426-3ab62398f080" width="1000" height="450" />  

Видно, что производительность ниже примерно в 2 раза, то есть можно предположить, что дальнейшее увеличение вычислительных возможностей Spark-кластера позволит более оперативно классифицировать транзакции.  

<ins>Отклонения от условий практического задания:</ins>  

В данном практическом задании не стал реализовывать задачу удаления кластера в Airflow, так как сама суть потоковой обработки не предусмативает такую логику. Работает бесконечный while-цикл, потребляющий новые данные из Кафки, а удаление нужно больше при пакетной обработке.

