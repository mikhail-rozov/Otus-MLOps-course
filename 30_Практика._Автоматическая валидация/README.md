Данное практическое задание во многом повторяет [предыдущую работу](https://github.com/mikhail-rozov/Otus-MLOps-course/tree/master/25_Практика_Регулярное%20переобучение).  
<br>
Скрипт DAG'а Airflow - [airflow_script.py](airflow_script.py)  
Скрипт очистки данных - [data_cleaning.py](data_cleaning.py)  
Скрипт обучения модели - [regular_refitting.py](regular_refitting.py)  
<br>
<ins>Что изменено:</ins>  
- Для тестовой выборки теперь не производится балансировка классов. Этому вопросу не было оказано должного внимания в предыдущей работе, балансировка тестовой выборки смещает оценку.  
- Добавлена стратификация выборок по целевой фиче. В предыдущей работе в этом не было нужды, так как все выборки балансировались.  

<ins>Что добавлено:</ins>  

Метрика теперь оценивается на бутстрап-выборках из тестовой выборки. Это делается для того, чтобы получить интервальную оценку и сравнить результаты модели после переобучения с лучшей моделью с помощью статистического теста. Используется t-тест для двух независимых выборок. Число бутстрап-выборок принято всего 10, чтобы расчёты выполнялись за разумное время. 10 выборок - достаточно малое количество для t-теста, так как при таком количестве трудно опереться на центральную предельную теорему и сказать, что распределение метрик этих выборок близко к нормальному, а t-тест подразумевает нормальность распределений. При достаточности времени и финансов на аренду мощностей, можно взять большее число бутстрап-выборок. По результатам t-теста принимается решение о сохранении модели в MLflow: если увеличение средней метрики значимо (уровень значимости принят 0.05), то модель сохраняется. Иначе используется предыдущая лучшая модель.

<ins>Как проверял:</ins>  

Вначале был сделан прогон на двух файлах данных. Как в предыдущей работе, но метрика рассчитывалась на бутстрап-выборках:  

Рисунок 1:  
<img src="https://github.com/user-attachments/assets/9cd5006d-276e-4d84-8a91-1f2e08979d9e" width="900" height="400" />  
<br>  
Рисунок 2:  
<br>  
<img src="https://github.com/user-attachments/assets/d1a288b8-4faa-4553-a42d-c3d04f7579aa" width="600" height="250" />  
<br> 
Далее добавил ещё один файл данных. При этом DAG Airflow сработал так, что при поступлении новых данных, эти данные обработались и добавились к уже имеющимся данным. Далее разветвление в DAG'е запустило переобучение модели на уже трёх файлах данных. Снова были получены метрики на бутстрап-выборках, а далее сделано сравнение средних метрик. Так как новые метрики оказались выше в абсолютном выражении, то запустился t-тест, который показал околонулевое значение p-value, что означает, что мы отвергаем нулевую гипотезу о том, что средние метрик выборок не отличаются. Новую модель сохранили в MLflow, который привязан к S3-хранилищу.  

Рисунок 3:  
<img src="https://github.com/user-attachments/assets/6abd9b61-abb2-4bb4-a142-6903c61d11d2" width="900" height="400" />  
<br>  
Рисунок 4. Околонулевое значение p-value:  
<br>  
<img src="https://github.com/user-attachments/assets/277d4c1d-52df-4954-bb8c-1a388e85ee81" width="1000" height="500" />  
Рисунок 5. Сохранённая модель в S3:  
<br>
<img src="https://github.com/user-attachments/assets/08c91667-9e08-4526-ab76-f690d2097200" width="600" height="250" />  

